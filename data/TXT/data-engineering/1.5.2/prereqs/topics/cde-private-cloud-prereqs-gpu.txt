Using GPUs in Cloudera Data Engineering (Technical Preview)Cloudera Docs
Using GPUs in Cloudera Data Engineering (Technical Preview)
A GPU is a specialized processor that can be used to accelerate highly parallelized
    computationally-intensive workloads. CDE leverages the Spark RAPIDS library to accelerate the
    Spark jobs and sessions using Nvidia GPUs.noteThis feature is in Technical Preview and not recommended for production deployments. Cloudera recommends that you try this feature in test or development environments.
GPU nodes setupYou can add the GPU hardware to the existing or new ECS or OCP cluster as a worker     node. Testing GPU setupBefore you create a CDE Data Service, as a Kubernetes administrator, you must ensure     that GPUs are advertised. Managing heterogenous GPU nodesIf you have heterogeneous GPU nodes and want to run Spark jobs or sessions on a     specific GPU node, then the Kubernetes platform administrator must add the node labels and     taints. Spark GPU Runtime ImagesThe Cloudera Spark GPU Runtime uses the "nvidia/cuda" option as a base image. The Spark     RAPIDS is built against Cloudera Spark distribution and is compatible with the Spark version     that Cloudera offers.Quota ManagementGPU resources are limited in the cluster and all Data Services, that is, CML and CDE     can share or dedicatedly set resource quota for their experience. Cloudera recommendeds to set     the GPU resource quota so that each data service can use the allocated GPU resources     effectively. Sharing GPU resources might lead to resource contention and delayed POD allocation. 