Testing GPU setupCloudera Docs
Testing GPU setup
Before you create a CDE Data Service, as a Kubernetes administrator, you must ensure
    that GPUs are advertised. 
You can test if the GPU resources are advertised by running a sample
        Pod:$ cat <<EOF | kubectl apply -f -

    apiVersion: v1
    kind: Pod
    metadata:
    name: gpu-pod
    spec:
    restartPolicy: Never
    containers:
    - name: cuda-container
    image: nvcr.io/nvidia/k8s/cuda-sample:vectoradd-cuda10.2
    resources:
    limits:
    nvidia.com/gpu: 1 # requesting 1 GPU
    EOF If you get an output similar to the following, it means that the GPU
        resources are ready for scheduling.// Log Output
        $ kubectl logs gpu-pod
        [Vector addition of 50000 elements]
        Copy input data from the host memory to the CUDA device
        CUDA kernel launch with 196 blocks of 256 threads
        Copy output data from the CUDA device to the host memory
        Test PASSED
        Done


Parent topic: Using GPUs in Cloudera Data Engineering (Technical Preview)